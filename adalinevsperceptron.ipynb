{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdGfBMcnb_O8"
      },
      "outputs": [],
      "source": [
        "# Task 3: Compare ADALINE vs Perceptron (2 features)\n",
        "# Run this cell/file independently\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Utilities\n",
        "def metrics_report(y_true, y_pred, pos_label=1, name=\"Model\"):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm  = confusion_matrix(y_true, y_pred, labels=[1, -1])\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"binary\", pos_label=pos_label, zero_division=0\n",
        "    )\n",
        "    print(f\"\\n=== {name} — Test Metrics ===\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}  Recall: {rec:.4f}  F1: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix (rows=[+1,-1], cols=[+1,-1]):\")\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,4))\n",
        "    im = ax.imshow(cm, interpolation=\"nearest\")\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    class_names = [\"+1\", \"-1\"]\n",
        "    ax.set(\n",
        "        xticks=np.arange(len(class_names)),\n",
        "        yticks=np.arange(len(class_names)),\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names,\n",
        "        xlabel=\"Predicted label\",\n",
        "        ylabel=\"True label\",\n",
        "        title=f\"{name} — Confusion Matrix\"\n",
        "    )\n",
        "    thresh = cm.max()/2 if cm.size else 0\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], \"d\"),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1, \"cm\": cm}\n",
        "\n",
        "def plot_histories(histories, title, ylabel=\"SSE or Mistakes\"):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    for label, values in histories.items():\n",
        "        plt.plot(range(1, len(values)+1), values, label=str(label))\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def make_iris_binary(two_features=True):\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    mask = (y == 0) | (y == 1)\n",
        "    X = X[mask]\n",
        "    y = y[mask]\n",
        "    y = np.where(y == 1, 1, -1)\n",
        "    if two_features:\n",
        "        X = X[:, [2, 3]]\n",
        "        feature_names = [\"petal length\", \"petal width\"]\n",
        "    else:\n",
        "        feature_names = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "    return X_train, X_test, y_train, y_test, feature_names\n",
        "\n",
        "# Models\n",
        "class AdalineManual:\n",
        "    def __init__(self, lr=0.01, epochs=100, random_state=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.random_state = random_state\n",
        "        self.w_ = None\n",
        "        self.b_ = 0.0\n",
        "        self.sse_history_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.w_ = rng.normal(0.0, 0.01, size=X.shape[1])\n",
        "        self.b_ = 0.0\n",
        "        self.sse_history_.clear()\n",
        "        for _ in range(self.epochs):\n",
        "            net = X @ self.w_ + self.b_\n",
        "            errors = y - net\n",
        "            self.w_ += self.lr * (X.T @ errors) / X.shape[0]\n",
        "            self.b_ += self.lr * errors.mean()\n",
        "            sse = float(np.sum(errors**2))\n",
        "            self.sse_history_.append(sse if np.isfinite(sse) else np.inf)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X @ self.w_ + self.b_ >= 0.0, 1, -1)\n",
        "\n",
        "class PerceptronManual:\n",
        "    \"\"\"Online perceptron with shuffling per epoch.\"\"\"\n",
        "    def __init__(self, lr=1.0, epochs=30, random_state=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.random_state = random_state\n",
        "        self.w_ = None\n",
        "        self.b_ = 0.0\n",
        "        self.mistakes_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.w_ = rng.normal(0.0, 0.01, size=X.shape[1])\n",
        "        self.b_ = 0.0\n",
        "        self.mistakes_.clear()\n",
        "        for _ in range(self.epochs):\n",
        "            idx = rng.permutation(X.shape[0])\n",
        "            mistakes = 0\n",
        "            for i in idx:\n",
        "                xi, yi = X[i], y[i]\n",
        "                if yi * (xi @ self.w_ + self.b_) <= 0:\n",
        "                    self.w_ += self.lr * yi * xi\n",
        "                    self.b_ += self.lr * yi\n",
        "                    mistakes += 1\n",
        "            self.mistakes_.append(mistakes)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X @ self.w_ + self.b_ >= 0.0, 1, -1)\n",
        "\n",
        "# Run\n",
        "if __name__ == \"__main__\":\n",
        "    Xtr, Xte, ytr, yte, feats = make_iris_binary(two_features=True)\n",
        "    print(f\"Compare on features: {feats}\")\n",
        "\n",
        "    adaline = AdalineManual(lr=0.01, epochs=100, random_state=RANDOM_STATE).fit(Xtr, ytr)\n",
        "    percep  = PerceptronManual(lr=1.0, epochs=30, random_state=RANDOM_STATE).fit(Xtr, ytr)\n",
        "\n",
        "    plot_histories({\"ADALINE SSE\": adaline.sse_history_},\n",
        "                   \"ADALINE — SSE vs Epochs (comparison)\", ylabel=\"SSE\")\n",
        "    plot_histories({\"Perceptron mistakes/epoch\": percep.mistakes_},\n",
        "                   \"Perceptron — Mistakes per Epoch (comparison)\", ylabel=\"Mistakes/epoch\")\n",
        "\n",
        "    _ = metrics_report(yte, adaline.predict(Xte), name=\"ADALINE (comparison)\")\n",
        "    _ = metrics_report(yte, percep.predict(Xte),  name=\"Perceptron (comparison)\")\n",
        "\n",
        "    def row(name, ytrue, ypred):\n",
        "        acc = accuracy_score(ytrue, ypred)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            ytrue, ypred, average=\"binary\", pos_label=1, zero_division=0\n",
        "        )\n",
        "        return {\"Model\": name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1}\n",
        "\n",
        "    summary_cmp = pd.DataFrame([\n",
        "        row(\"ADALINE\", yte, adaline.predict(Xte)),\n",
        "        row(\"Perceptron\", yte, percep.predict(Xte)),\n",
        "    ])\n",
        "    print(\"\\n=== Comparison Summary (2 features) ===\")\n",
        "    print(summary_cmp.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ErcbK8s6cFg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}