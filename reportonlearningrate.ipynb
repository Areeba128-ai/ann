{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k7rX1zVcJWX"
      },
      "outputs": [],
      "source": [
        "# Task 4: η effects and metrics (2 features)\n",
        "# Run this cell/file independently\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Utilities\n",
        "def plot_histories(histories, title, ylabel):\n",
        "    plt.figure(figsize=(7,5))\n",
        "    for label, values in histories.items():\n",
        "        plt.plot(range(1, len(values)+1), values, label=str(label))\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def make_iris_binary(two_features=True):\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    mask = (y == 0) | (y == 1)\n",
        "    X = X[mask]\n",
        "    y = y[mask]\n",
        "    y = np.where(y == 1, 1, -1)\n",
        "    if two_features:\n",
        "        X = X[:, [2, 3]]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test  = scaler.transform(X_test)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Models\n",
        "class AdalineManual:\n",
        "    def __init__(self, lr=0.01, epochs=100, random_state=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.random_state = random_state\n",
        "        self.w_ = None\n",
        "        self.b_ = 0.0\n",
        "        self.sse_history_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.w_ = rng.normal(0.0, 0.01, size=X.shape[1])\n",
        "        self.b_ = 0.0\n",
        "        self.sse_history_.clear()\n",
        "        for _ in range(self.epochs):\n",
        "            net = X @ self.w_ + self.b_\n",
        "            errors = y - net\n",
        "            self.w_ += self.lr * (X.T @ errors) / X.shape[0]\n",
        "            self.b_ += self.lr * errors.mean()\n",
        "            self.sse_history_.append(float(np.sum(errors**2)))\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X @ self.w_ + self.b_ >= 0.0, 1, -1)\n",
        "\n",
        "class PerceptronManual:\n",
        "    def __init__(self, lr=1.0, epochs=30, random_state=0):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.random_state = random_state\n",
        "        self.w_ = None\n",
        "        self.b_ = 0.0\n",
        "        self.mistakes_ = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.w_ = rng.normal(0.0, 0.01, size=X.shape[1])\n",
        "        self.b_ = 0.0\n",
        "        self.mistakes_.clear()\n",
        "        for _ in range(self.epochs):\n",
        "            idx = rng.permutation(X.shape[0])\n",
        "            mistakes = 0\n",
        "            for i in idx:\n",
        "                xi, yi = X[i], y[i]\n",
        "                if yi * (xi @ self.w_ + self.b_) <= 0:\n",
        "                    self.w_ += self.lr * yi * xi\n",
        "                    self.b_ += self.lr * yi\n",
        "                    mistakes += 1\n",
        "            self.mistakes_.append(mistakes)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(X @ self.w_ + self.b_ >= 0.0, 1, -1)\n",
        "\n",
        "# Run\n",
        "if __name__ == \"__main__\":\n",
        "    Xtr, Xte, ytr, yte = make_iris_binary(two_features=True)\n",
        "    etas = [0.001, 0.01, 0.1, 1.0]\n",
        "\n",
        "    hist_adaline, rows_adaline = {}, []\n",
        "    for eta in etas:\n",
        "        m = AdalineManual(lr=eta, epochs=100, random_state=RANDOM_STATE).fit(Xtr, ytr)\n",
        "        hist_adaline[f\"η={eta}\"] = m.sse_history_\n",
        "        pred = m.predict(Xte)\n",
        "        acc = accuracy_score(yte, pred)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            yte, pred, average=\"binary\", pos_label=1, zero_division=0\n",
        "        )\n",
        "        rows_adaline.append({\"Model\":\"ADALINE\", \"η\":eta, \"Accuracy\":acc, \"Precision\":prec, \"Recall\":rec, \"F1\":f1})\n",
        "\n",
        "    plot_histories(hist_adaline, \"ADALINE — SSE vs Epochs (η sweep)\", ylabel=\"SSE\")\n",
        "    df_adaline = pd.DataFrame(rows_adaline).sort_values([\"F1\",\"Accuracy\"], ascending=[False, False])\n",
        "    print(\"\\n=== η Effects — ADALINE (2 features) ===\")\n",
        "    print(df_adaline.to_string(index=False))\n",
        "\n",
        "    hist_perc, rows_perc = {}, []\n",
        "    for eta in etas:\n",
        "        p = PerceptronManual(lr=eta, epochs=30, random_state=RANDOM_STATE).fit(Xtr, ytr)\n",
        "        hist_perc[f\"η={eta}\"] = p.mistakes_\n",
        "        pred = p.predict(Xte)\n",
        "        acc = accuracy_score(yte, pred)\n",
        "        prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "            yte, pred, average=\"binary\", pos_label=1, zero_division=0\n",
        "        )\n",
        "        rows_perc.append({\"Model\":\"Perceptron\", \"η\":eta, \"Accuracy\":acc, \"Precision\":prec, \"Recall\":rec, \"F1\":f1})\n",
        "\n",
        "    plot_histories(hist_perc, \"Perceptron — Mistakes per Epoch (η sweep)\", ylabel=\"Mistakes/epoch\")\n",
        "    df_perc = pd.DataFrame(rows_perc).sort_values([\"F1\",\"Accuracy\"], ascending=[False, False])\n",
        "    print(\"\\n=== η Effects — Perceptron (2 features) ===\")\n",
        "    print(df_perc.to_string(index=False))\n",
        "\n",
        "    best_a = df_adaline.iloc[0].to_dict()\n",
        "    best_p = df_perc.iloc[0].to_dict()\n",
        "    print(\"\\n=== Best η Summary ===\")\n",
        "    print(pd.DataFrame([best_a, best_p]).to_string(index=False))\n"
      ]
    }
  ]
}